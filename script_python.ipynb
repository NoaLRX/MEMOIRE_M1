{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Food</th>\n",
       "      <th>Metal</th>\n",
       "      <th>Raw_Material</th>\n",
       "      <th>Vege_Oil</th>\n",
       "      <th>Wheat</th>\n",
       "      <th>Sugar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.6</td>\n",
       "      <td>-1.219457</td>\n",
       "      <td>-0.416637</td>\n",
       "      <td>-4.547213</td>\n",
       "      <td>-38.25</td>\n",
       "      <td>-0.803987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.4</td>\n",
       "      <td>-0.534472</td>\n",
       "      <td>0.192139</td>\n",
       "      <td>1.536119</td>\n",
       "      <td>43.00</td>\n",
       "      <td>0.217061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.2</td>\n",
       "      <td>1.041869</td>\n",
       "      <td>-0.470108</td>\n",
       "      <td>-0.569695</td>\n",
       "      <td>-21.25</td>\n",
       "      <td>-0.251899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.4</td>\n",
       "      <td>2.125080</td>\n",
       "      <td>1.500506</td>\n",
       "      <td>-0.983030</td>\n",
       "      <td>-6.75</td>\n",
       "      <td>-0.356486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.8</td>\n",
       "      <td>0.495689</td>\n",
       "      <td>1.973461</td>\n",
       "      <td>-1.282328</td>\n",
       "      <td>-2.25</td>\n",
       "      <td>0.103442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Food     Metal  Raw_Material  Vege_Oil  Wheat     Sugar\n",
       "0  -2.6 -1.219457     -0.416637 -4.547213 -38.25 -0.803987\n",
       "1  -1.4 -0.534472      0.192139  1.536119  43.00  0.217061\n",
       "2  -1.2  1.041869     -0.470108 -0.569695 -21.25 -0.251899\n",
       "3  -0.4  2.125080      1.500506 -0.983030  -6.75 -0.356486\n",
       "4  -0.8  0.495689      1.973461 -1.282328  -2.25  0.103442"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/Users/noa/Desktop/MEMOIRE/DATA/df_clean_vfinal.csv\",sep=\";\")\n",
    "df_clean = df.drop('Unnamed: 0', axis=1)\n",
    "df_clean.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0) # pour la reproductibilité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-18 12:50:44.781894: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-18 12:50:44.783933: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-18 12:50:44.785222: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-18 12:50:45.625393: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-18 12:50:45.627220: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-18 12:50:45.628699: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-18 12:50:46.235116: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-18 12:50:46.236380: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-18 12:50:46.237753: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 2s 2ms/step - loss: 4.7418\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.6233\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.5484\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.5111\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.4840\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.4689\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 4.4497\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.4303\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.4075\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.3840\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.3710\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.3403\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.3164\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.2902\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.2611\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.2354\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.1973\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.1748\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.1216\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.0955\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.0413\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.9965\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.9592\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.9423\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.8546\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.9253\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.7471\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.7117\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.6619\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.6105\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.5486\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.4982\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.4514\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.3897\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 3.3546\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 3.2873\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.2657\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.2581\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.1577\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.1325\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.0901\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.0710\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.0194\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.0329\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.9648\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.9410\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.9240\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.9155\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.9116\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8692\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8555\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8496\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.8340\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8732\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8172\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8117\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7930\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.7958\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7659\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7680\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7768\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7590\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7748\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.7534\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7457\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7434\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7601\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.7562\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7371\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7757\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8398\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.7283\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7172\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7454\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7324\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 2.7113\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7698\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7209\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7401\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7031\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7213\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7128\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7614\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7334\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.6926\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7596\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7220\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7346\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7093\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 2.7146\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7131\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7358\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.6908\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7001\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7077\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.6969\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7032\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7021\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7214\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.6818\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x162479f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-18 12:50:52.839684: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-18 12:50:52.840981: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-18 12:50:52.843113: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "# Sélectionner les variables explicatives et dépendante\n",
    "X = df_clean.drop('Food', axis=1).values\n",
    "y = df_clean['Food'].values\n",
    "\n",
    "# Mettre à l'échelle les données entre 0 et 1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Redimensionner les données pour le LSTM [samples, time steps, features]\n",
    "X = np.reshape(X, (X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "# Déterminer le nombre d'observations à utiliser pour l'entraînement\n",
    "train_size = int(len(df_clean) * 0.8)\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test = X[0:train_size], X[train_size:len(X)]\n",
    "y_train, y_test = y[0:train_size], y[train_size:len(y)]\n",
    "\n",
    "# Créer le modèle LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Entraîner le modèle\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=8, verbose=1)\n",
    "\n",
    "# Prédire les valeurs de y pour l'ensemble de test\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.25294527],\n",
       "       [ 0.1913026 ],\n",
       "       [ 0.19904342],\n",
       "       [-0.8268727 ],\n",
       "       [-1.011227  ],\n",
       "       [-0.39776492],\n",
       "       [-0.02392626],\n",
       "       [ 0.39662206],\n",
       "       [-0.6282057 ],\n",
       "       [-1.1094687 ],\n",
       "       [ 0.5260734 ],\n",
       "       [-0.27537918],\n",
       "       [ 0.71199733],\n",
       "       [-0.72112125],\n",
       "       [-0.06165266],\n",
       "       [ 0.42729592],\n",
       "       [-0.32099512],\n",
       "       [-1.6836557 ],\n",
       "       [ 1.7716432 ],\n",
       "       [ 0.70828897],\n",
       "       [ 0.9745996 ],\n",
       "       [ 1.648176  ],\n",
       "       [-0.82380736],\n",
       "       [-2.2641864 ],\n",
       "       [-2.5867476 ],\n",
       "       [-1.8876078 ],\n",
       "       [ 1.2354914 ],\n",
       "       [ 2.109305  ],\n",
       "       [ 2.9924333 ],\n",
       "       [ 2.9692073 ],\n",
       "       [ 1.0942109 ],\n",
       "       [ 1.2744782 ],\n",
       "       [ 2.3110309 ],\n",
       "       [ 3.50036   ],\n",
       "       [ 1.1870283 ],\n",
       "       [ 2.5313935 ],\n",
       "       [ 0.01085046],\n",
       "       [ 3.6764412 ],\n",
       "       [ 2.58707   ],\n",
       "       [ 0.752668  ],\n",
       "       [ 0.7087133 ],\n",
       "       [-0.13846439],\n",
       "       [ 0.11906552],\n",
       "       [ 2.568086  ],\n",
       "       [-1.6623497 ],\n",
       "       [-0.4145909 ],\n",
       "       [ 3.147168  ],\n",
       "       [ 2.1032424 ],\n",
       "       [ 1.8134997 ],\n",
       "       [-0.12308434],\n",
       "       [-2.4711754 ],\n",
       "       [-1.7596309 ],\n",
       "       [-2.1869128 ],\n",
       "       [ 0.9053879 ],\n",
       "       [-2.7402458 ],\n",
       "       [-1.2519723 ],\n",
       "       [ 1.836103  ],\n",
       "       [ 2.1176233 ]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 1.995\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# Calculer le RMSE\n",
    "rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('Test RMSE: %.3f' % rmse) \n",
    "# On trouve 2.043 avec 200\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle LSTM-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from project/Air Quality Index/tuner0.json\n",
      "Search space summary\n",
      "Default search space size: 5\n",
      "conv_1_filter (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 16, 'sampling': 'linear'}\n",
      "conv_1_kernel (Choice)\n",
      "{'default': 3, 'conditions': [], 'values': [3, 5], 'ordered': True}\n",
      "lstm_1_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 16, 'sampling': 'linear'}\n",
      "dense_1_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 16, 'sampling': 'linear'}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 12:15:29.633033: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-24 12:15:29.634366: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-24 12:15:29.635402: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-24 12:15:30.113201: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-24 12:15:30.116418: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-24 12:15:30.121852: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-24 12:15:31.412569: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-24 12:15:31.415835: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-24 12:15:31.417623: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - ETA: 0s - loss: 4.5076 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 12:15:33.537670: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-24 12:15:33.540050: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-24 12:15:33.541505: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 4s 116ms/step - loss: 4.5076 - val_loss: 4.4764\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 4.1332 - val_loss: 4.3417\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.9612 - val_loss: 4.2221\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.7185 - val_loss: 4.0349\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.4287 - val_loss: 3.9165\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3.2700 - val_loss: 3.8883\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.9824 - val_loss: 4.0184\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.9071 - val_loss: 4.2101\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.8687 - val_loss: 4.1882\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.8992 - val_loss: 4.2007\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 2.8876 - val_loss: 4.2389\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 2.7841 - val_loss: 4.3140\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 38ms/step - loss: 2.7804 - val_loss: 4.4094\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 2.9022 - val_loss: 4.3545\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.9062 - val_loss: 4.3584\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.8605 - val_loss: 4.2585\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.7296 - val_loss: 4.2332\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.7048 - val_loss: 4.1293\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.6947 - val_loss: 4.3399\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.6537 - val_loss: 4.3324\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.5957 - val_loss: 4.2725\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.5789 - val_loss: 4.1967\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.6035 - val_loss: 4.1826\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.5750 - val_loss: 4.3089\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.5238 - val_loss: 4.3739\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.5361 - val_loss: 4.3435\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.6478 - val_loss: 4.2916\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.6212 - val_loss: 4.3336\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 2.5230 - val_loss: 4.2669\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 2.5329 - val_loss: 4.1499\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.6011 - val_loss: 4.1519\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 2.6246 - val_loss: 4.1594\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.4774 - val_loss: 4.2405\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 2.4699 - val_loss: 4.2071\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.5665 - val_loss: 4.1256\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 2.3474 - val_loss: 4.1465\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.3336 - val_loss: 4.1046\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.3632 - val_loss: 4.1071\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 2.3377 - val_loss: 4.0398\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.4065 - val_loss: 4.0468\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.3940 - val_loss: 4.1011\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.3714 - val_loss: 4.0197\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.2768 - val_loss: 4.0555\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.2291 - val_loss: 4.2840\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.2646 - val_loss: 4.3189\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.1699 - val_loss: 4.2537\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.1841 - val_loss: 4.1359\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.1601 - val_loss: 4.1893\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.0887 - val_loss: 4.3066\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.0765 - val_loss: 4.3472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 12:15:39.273989: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-24 12:15:39.276498: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-24 12:15:39.278367: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 4ms/step\n",
      "Root Mean Squared Error:  2.084983801304198\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Charger les données\n",
    "df = pd.read_csv(\"/Users/noa/Desktop/MEMOIRE/DATA/df_clean_vfinal.csv\",sep=\";\")\n",
    "df_clean = df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# Choisir les variables explicatives et la variable à prédire\n",
    "X = df_clean.drop('Food', axis=1)\n",
    "y = df_clean['Food']\n",
    "\n",
    "# Définir le nombre de lignes pour le jeu de données d'entraînement\n",
    "n_train = int(round(0.8 * len(df_clean)))\n",
    "\n",
    "# Créer les jeux de données d'entraînement et de test\n",
    "X_train, X_test = X[:n_train], X[n_train:]\n",
    "y_train, y_test = y[:n_train], y[n_train:]\n",
    "\n",
    "# Redimensionner les données pour LSTM et CNN\n",
    "X_train = np.array(X_train).reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = np.array(X_test).reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=hp.Int('conv_1_filter', min_value=32, max_value=128, step=16),\n",
    "                     kernel_size=hp.Choice('conv_1_kernel', values = [3,5]),\n",
    "                     activation='relu',\n",
    "                     input_shape=(X_train.shape[1], 1)\n",
    "                     )\n",
    "              )\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(LSTM(units=hp.Int('lstm_1_units', min_value=32, max_value=128, step=16), \n",
    "                   return_sequences=True))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=hp.Int('dense_1_units', min_value=32, max_value=128, step=16),\n",
    "                    activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer=Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "                  loss='mean_squared_error')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Fixer le seed pour la reproductibilité\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "tuner = kt.RandomSearch(build_model,\n",
    "                        objective='val_loss',\n",
    "                        max_trials=5,\n",
    "                        executions_per_trial=3,\n",
    "                        directory='project',\n",
    "                        project_name='Air Quality Index')\n",
    "\n",
    "tuner.search_space_summary()\n",
    "\n",
    "tuner.search(X_train, y_train, epochs=50, validation_data=(X_test, y_test))\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test))\n",
    "\n",
    "# Prédire les valeurs du test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculer le RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error: ', rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.091953  ],\n",
       "       [-0.72839725],\n",
       "       [-0.5352354 ],\n",
       "       [ 0.92883587],\n",
       "       [-0.23568402],\n",
       "       [-0.32293752],\n",
       "       [-0.44863686],\n",
       "       [-0.79573154],\n",
       "       [-0.71900046],\n",
       "       [ 0.62138724],\n",
       "       [-1.3332232 ],\n",
       "       [-0.1854998 ],\n",
       "       [-0.7409215 ],\n",
       "       [ 0.63770485],\n",
       "       [ 0.23270388],\n",
       "       [-0.9761145 ],\n",
       "       [-0.5748418 ],\n",
       "       [ 1.8693148 ],\n",
       "       [ 0.28801283],\n",
       "       [ 0.5781991 ],\n",
       "       [ 2.2608652 ],\n",
       "       [-2.1593468 ],\n",
       "       [-1.9919473 ],\n",
       "       [-1.5050828 ],\n",
       "       [-1.8122737 ],\n",
       "       [ 0.2286975 ],\n",
       "       [ 3.2927022 ],\n",
       "       [ 4.076152  ],\n",
       "       [ 3.171388  ],\n",
       "       [ 1.3131952 ],\n",
       "       [ 0.755734  ],\n",
       "       [ 1.4816917 ],\n",
       "       [ 5.2486362 ],\n",
       "       [ 0.9899173 ],\n",
       "       [ 2.1440265 ],\n",
       "       [-0.3817432 ],\n",
       "       [ 3.06019   ],\n",
       "       [ 0.21716091],\n",
       "       [ 0.8876405 ],\n",
       "       [ 0.36461273],\n",
       "       [-0.56848276],\n",
       "       [ 0.02294786],\n",
       "       [ 3.9699364 ],\n",
       "       [-2.5735354 ],\n",
       "       [-0.7777506 ],\n",
       "       [ 2.6409261 ],\n",
       "       [ 1.7258118 ],\n",
       "       [ 3.6129577 ],\n",
       "       [ 0.7428874 ],\n",
       "       [-0.5376136 ],\n",
       "       [-1.3891581 ],\n",
       "       [-2.623395  ],\n",
       "       [ 0.9359765 ],\n",
       "       [-0.6874553 ],\n",
       "       [-1.3805827 ],\n",
       "       [-1.0830053 ],\n",
       "       [ 2.4709365 ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 01s]\n",
      "\n",
      "Best val_loss So Far: 2.7803364594777427\n",
      "Total elapsed time: 00h 01m 26s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 12:21:12.586996: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-24 12:21:12.591899: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-24 12:21:12.596393: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 12:21:13.233957: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-24 12:21:13.237238: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-24 12:21:13.240281: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-24 12:21:14.677170: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-24 12:21:14.679213: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-24 12:21:14.681583: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8 [==>...........................] - ETA: 23s - loss: 4.7453"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 12:21:16.667348: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-24 12:21:16.669420: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-24 12:21:16.671743: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 4s 111ms/step - loss: 4.5749 - val_loss: 4.2603\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 3.7953 - val_loss: 4.4879\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 3.5649 - val_loss: 4.4144\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 3.4827 - val_loss: 4.3235\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 3.3184 - val_loss: 4.5743\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 3.8268 - val_loss: 4.5346\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.3376 - val_loss: 4.5906\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 3.2141 - val_loss: 4.4416\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 3.0879 - val_loss: 4.6162\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 3.0114 - val_loss: 4.8087\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 3.0580 - val_loss: 4.5241\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.8939 - val_loss: 5.0478\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 2.9794 - val_loss: 4.4240\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 2.6919 - val_loss: 5.1822\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.9767 - val_loss: 4.4283\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 3.0223 - val_loss: 4.3777\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.8416 - val_loss: 4.5270\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.6823 - val_loss: 5.3024\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.8652 - val_loss: 4.6094\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 2.4992 - val_loss: 4.3570\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 2.3185 - val_loss: 4.5697\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.2507 - val_loss: 4.2140\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.4574 - val_loss: 4.3166\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.6902 - val_loss: 4.8085\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.9522 - val_loss: 4.1197\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.4804 - val_loss: 4.3516\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 2.3163 - val_loss: 4.0634\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.4268 - val_loss: 4.1239\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 2.0382 - val_loss: 4.4541\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.9827 - val_loss: 3.8722\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.8675 - val_loss: 4.9589\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.1327 - val_loss: 3.8950\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.0949 - val_loss: 4.1341\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.8656 - val_loss: 4.1241\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.8216 - val_loss: 4.4690\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.8400 - val_loss: 3.8971\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.9516 - val_loss: 4.0154\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.2194 - val_loss: 3.9981\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.7485 - val_loss: 3.8633\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.6882 - val_loss: 4.1512\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.7797 - val_loss: 4.0892\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.8531 - val_loss: 3.8164\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.0898 - val_loss: 4.1137\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.2879 - val_loss: 4.0984\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.5825 - val_loss: 4.1033\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.3627 - val_loss: 3.6362\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 2.1941 - val_loss: 3.8375\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.9453 - val_loss: 3.5516\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.6730 - val_loss: 3.8450\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.6430 - val_loss: 3.8620\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1649dcf40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 12:21:26.335083: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-24 12:21:26.337025: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-24 12:21:26.339354: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error:  1.9652070392031626\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Charger les données\n",
    "df = pd.read_csv(\"/Users/noa/Desktop/MEMOIRE/DATA/df_clean_vfinal.csv\",sep=\";\")\n",
    "df_clean = df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# Choisir les variables explicatives et la variable à prédire\n",
    "X = df_clean.drop('Food', axis=1)\n",
    "y = df_clean['Food']\n",
    "\n",
    "# Définir le nombre de lignes pour le jeu de données d'entraînement\n",
    "n_train = int(round(0.8 * len(df_clean)))\n",
    "\n",
    "# Créer les jeux de données d'entraînement et de test\n",
    "X_train, X_test = X[:n_train], X[n_train:]\n",
    "y_train, y_test = y[:n_train], y[n_train:]\n",
    "\n",
    "# Redimensionner les données pour LSTM et CNN\n",
    "X_train = np.array(X_train).reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = np.array(X_test).reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=hp.Int('conv_1_filter', min_value=32, max_value=128, step=16),\n",
    "                     kernel_size=hp.Choice('conv_1_kernel', values = [3,5]),\n",
    "                     activation='relu',\n",
    "                     input_shape=(X_train.shape[1], 1)\n",
    "                     )\n",
    "              )\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(LSTM(units=hp.Int('lstm_1_units', min_value=32, max_value=128, step=16), \n",
    "                   return_sequences=True))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=hp.Int('dense_1_units', min_value=32, max_value=128, step=16),\n",
    "                    activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer=Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "                  loss='mean_squared_error')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Fixer le seed pour la reproductibilité\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "tuner = kt.RandomSearch(build_model,\n",
    "                        objective='val_loss',\n",
    "                        max_trials=5,\n",
    "                        executions_per_trial=3,\n",
    "                        directory='project',\n",
    "                        project_name='Food Prediction')\n",
    "\n",
    "tuner.search_space_summary()\n",
    "\n",
    "tuner.search(X_train, y_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test))\n",
    "\n",
    "# Prédire les valeurs du test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculer le RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error: ', rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9445525 ],\n",
       "       [-0.93539023],\n",
       "       [ 0.1849516 ],\n",
       "       [-0.5293375 ],\n",
       "       [ 0.25189877],\n",
       "       [-0.01561911],\n",
       "       [ 0.5863977 ],\n",
       "       [-0.7480756 ],\n",
       "       [-1.245021  ],\n",
       "       [-0.41833475],\n",
       "       [-0.382944  ],\n",
       "       [-0.4456981 ],\n",
       "       [-0.5368668 ],\n",
       "       [ 0.2550073 ],\n",
       "       [ 0.6520901 ],\n",
       "       [-0.4694371 ],\n",
       "       [-0.7398653 ],\n",
       "       [ 2.4111953 ],\n",
       "       [ 1.0097945 ],\n",
       "       [ 1.1524918 ],\n",
       "       [ 3.8888113 ],\n",
       "       [-1.0083015 ],\n",
       "       [-3.4491544 ],\n",
       "       [-1.2592658 ],\n",
       "       [-2.023909  ],\n",
       "       [-0.11957505],\n",
       "       [ 2.1137626 ],\n",
       "       [ 4.4485235 ],\n",
       "       [ 3.6021113 ],\n",
       "       [ 1.7200509 ],\n",
       "       [ 1.4683067 ],\n",
       "       [ 1.1919237 ],\n",
       "       [ 4.8188577 ],\n",
       "       [ 1.0666952 ],\n",
       "       [ 4.31144   ],\n",
       "       [ 0.45934787],\n",
       "       [ 3.7395496 ],\n",
       "       [ 2.0674832 ],\n",
       "       [ 0.878674  ],\n",
       "       [ 0.9505762 ],\n",
       "       [-0.6655151 ],\n",
       "       [ 0.40474814],\n",
       "       [ 3.820584  ],\n",
       "       [-1.0126293 ],\n",
       "       [ 0.76504004],\n",
       "       [ 4.6035447 ],\n",
       "       [ 3.697545  ],\n",
       "       [ 1.6867605 ],\n",
       "       [ 0.620801  ],\n",
       "       [-0.837868  ],\n",
       "       [-2.5649328 ],\n",
       "       [-1.3666286 ],\n",
       "       [ 0.28617516],\n",
       "       [-1.1662878 ],\n",
       "       [-1.1604571 ],\n",
       "       [ 0.373197  ],\n",
       "       [ 1.4121791 ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle TDNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rn/6p197mt917g87n_v871v7zbm0000gn/T/ipykernel_26225/1337302335.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=build_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x162dbb100> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x1617de520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Meilleur: -3.722276 using {'batch_size': 32, 'epochs': 50, 'filters': 32, 'kernel_size': 3}\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x16454c7c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Root Mean Squared Error:  2.077959658985974\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "# Charger les données\n",
    "df = pd.read_csv(\"/Users/noa/Desktop/MEMOIRE/DATA/df_clean_vfinal.csv\",sep=\";\")\n",
    "df_clean = df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# Choisir les variables explicatives et la variable à prédire\n",
    "X = df_clean.drop('Food', axis=1)\n",
    "y = df_clean['Food']\n",
    "\n",
    "# Définir le nombre de lignes pour le jeu de données d'entraînement\n",
    "n_train = int(round(0.8 * len(df_clean)))\n",
    "\n",
    "# Créer les jeux de données d'entraînement et de test\n",
    "X_train, X_test = X[:n_train], X[n_train:]\n",
    "y_train, y_test = y[:n_train], y[n_train:]\n",
    "\n",
    "# Redimensionner les données pour TDNN\n",
    "X_train = np.array(X_train).reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = np.array(X_test).reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "def build_model(filters=64, kernel_size=3):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu',\n",
    "                     input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=Adam(), loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Fixer le seed pour la reproductibilité\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = KerasRegressor(build_fn=build_model, verbose=0)\n",
    "\n",
    "param_grid = {'filters': [32, 64],\n",
    "              'kernel_size': [3, 5],\n",
    "              'batch_size': [16, 32],\n",
    "              'epochs': [50]}\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Résumer les résultats\n",
    "print(\"Meilleur: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# Prédire les valeurs du test\n",
    "y_pred = grid_result.predict(X_test)\n",
    "\n",
    "# Calculer le RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error: ', rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.07985413e-01,  3.33599979e-03, -2.92347789e-01, -1.46968916e-01,\n",
       "       -4.05041456e-01,  1.65459916e-01,  2.19096348e-01, -6.75913870e-01,\n",
       "       -7.79835522e-01,  3.45027715e-01,  1.10902354e-01,  2.84335107e-01,\n",
       "       -7.03700840e-01,  7.57592171e-02,  5.63352823e-01,  5.53352125e-02,\n",
       "       -1.23081803e+00,  1.62371016e+00,  5.58248580e-01,  5.57829380e-01,\n",
       "        1.67949510e+00, -1.16999519e+00, -2.09849787e+00, -1.66773427e+00,\n",
       "       -1.92132199e+00,  1.37285733e+00,  2.26397514e+00,  2.93092966e+00,\n",
       "        2.75523543e+00,  1.17755604e+00,  8.59995127e-01,  2.60150671e+00,\n",
       "        3.79556036e+00,  1.14183331e+00,  2.06639147e+00,  5.91061413e-01,\n",
       "        3.66256642e+00,  3.33346605e+00,  7.87963331e-01,  6.29693449e-01,\n",
       "       -1.01111698e+00,  4.45776954e-02,  2.98684454e+00, -1.75311160e+00,\n",
       "       -1.96950566e-02,  4.05976820e+00,  2.37461448e+00,  2.17771530e+00,\n",
       "       -1.44315492e-02, -2.35928488e+00, -1.24224746e+00, -1.58348989e+00,\n",
       "        1.17609847e+00, -2.49610615e+00, -1.25575590e+00,  1.58624673e+00,\n",
       "        2.02249050e+00], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
